\begin{thebibliography}{1}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{bostan2017}
L.~A.~M. Bostan, ``Ingredient-driven recipe generation using neural and
  distributional models,'' Master's thesis, University of Trento, July 2017.
 \begin{quotation}\noindent In this paper Bostan investigates computational
  ability to generate recipe instructions as natural language from a set of
  ingredients. The primary focus is on connecting ingredients with semantic
  instructions and finding ways to connect those instructions into sensible
  event chains. These event chains are then translated into natural language
  using standard distrobutional naturual language processing techniques such as
  word2vec and bag of words. Section one introduces the motivation and details
  the research question. The goal is to generate recipes utilizing data from
  aggregated recipes using unsupervised learning techniques. Section two gives
  a history of related work and details the inspiration for many of the
  techniques utilized. Section three describes the datasets used. Public
  datasets of recipes such as OpenRecipes and Now you're cooking provide about
  200,000 recipes for processing. This section also details the general
  data-wrangling techniques and generalized statistics. Bostan also found
  cuisine can be identified from the ingredients of the recipe. Section four
  details the methods of the study. Botan created two co-occurrence matrices.
  One counting the pairs of co-occurring ingredients and the other counting
  pairs of ingredient - action (ie. stir, bake, whisk) occurrences. To create
  the ingredient vector space, Bostan reduced the dimension of the Ingredient
  matrix using singular value decomposition. This information is used to train
  an architecture or recurrent neural network called a Long-short-term memory
  network. To test the network, Bostan trained on 80\% of the data then tried
  to generate instructions for the remaining recipes. Bostan found promising
  results but left many components to future research. \end{quotation}

\end{thebibliography}
